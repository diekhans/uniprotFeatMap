#!/usr/bin/env python3

import sys
import os.path as osp
import argparse
import re
import pipettor
from Bio import SeqIO
from pycbio.sys import fileOps

sys.path.insert(0, osp.normpath(osp.join(osp.dirname(__file__), "../lib")))
from protmap import conf, prMsg
from protmap.depends import runIfNotDone, runIfOutOfDate
from protmap.align import querySplit, runBatch, buildBlastTransIndex

uniprotProteinTranscriptAlignJob = osp.join(osp.dirname(__file__), "uniprotProteinTranscriptAlignJob")

# Note:
#  - Don't filter for minimum alignment coverage to get alt isoforms, which
#    are often split

def parseArgs():
    desc = """Align UniProt protein sequences to transcript RNAs with BLAT or
    BLAST.  Creates a protein to NA PSL alignments, with some basic filtering.
    UTR is hard masked to prevent alignment outside of CDS without changing
    sequence size.

    Program can rerun to finish up after manual parasol recovery, checking
    for the state of the result files.  After returning a files could,
    touch ${workdir}/aligns.doneto indicate where to
    """
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("--algo", choices=("blast", "blat"), default="blat",
                        help="alignment algorithm")
    parser.add_argument("uniprotFa",
                        help="uniprotFa FASTA")
    parser.add_argument("transFa",
                        help="transcript FASTA")
    parser.add_argument("protTransPsl",
                        help="alignments, sorted by transcript")
    parser.add_argument("workDir",
                        help="temporary directory used by parasol run")
    return parser.parse_args()

def parseGencodeFastaHeaderCds(parts):
    for elem in parts:
        m = re.search("^CDS:([0-9]+)-([0-9]+)$", elem)
        if m is not None:
            return int(m.group(1)) - 1, int(m.group(2))  # zero-based
    return None

def parseGencodeFastaHeader(rec):
    """parse the fasta, returning new id and CDS coordinates (or None if no CDS)
      >ENST00000641515.2|ENSG00000186092.7|OTTHUMG00000001094.4|OTTHUMT00000003223.4|OR4F5-201|OR4F5|2618|UTR5:1-60|CDS:61-1041|UTR3:1042-2618|
    """
    parts = rec.id.split('|')
    cds = parseGencodeFastaHeaderCds(parts)
    return parts[0], cds

def maskUtr(seq, cds):
    return (cds[0] * 'N') + seq[cds[0]:cds[1]] + ((len(seq) - cds[1]) * 'N')

def editGencodeFastaRec(rec, outFh):
    transId, cds = parseGencodeFastaHeader(rec)
    if cds is not None:
        print(">" + transId, file=outFh)
        print(maskUtr(rec.seq, cds), file=outFh)


def editGencodeFasta(inFa, outFa):
    """
    Decompress and parse GENCODE FASTA headers to get basic id. The UTR
    regions will be masked, sequences without CDS noted in the header are
    discarded.
    """
    with fileOps.opengz(inFa) as inFh:
        with fileOps.opengz(outFa, 'w') as outFh:
            for rec in SeqIO.parse(inFh, "fasta"):
                editGencodeFastaRec(rec, outFh)

def targetBuildDb(transFa, transDbFa, algo, targetDir):
    prMsg("building target transcript database")
    fileOps.ensureDir(targetDir)
    fileOps.ensureFileDir(transDbFa)
    editGencodeFasta(transFa, transDbFa)
    if algo == "blast":
        buildBlastTransIndex(transDbFa, targetDir)

def queryBuildDb(uniprotFa, queryDir):
    """
    Output and split canonical isoform records.  They which have headers like
    >P14060 isRefOf P14060
    """
    prMsg("split UniProt proteins")
    querySplit(uniprotFa, queryDir, filterFunc=lambda hline: re.match("^>.+ isRefOf .+$", hline))

def combineAligns(alignDir, protTransPsl):
    "concatenate and sort by tName (transcript))"
    prMsg("combining alignments")

    # discard not within the configure minimum identity and coverage.  Batch
    # program discards PSLs that are not ++ alignments
    pipettor.run([["find", alignDir, "-name", "*.fa.psl", "-print0"],
                  ["sort", "-k14,14", "-k10,10", "--files0-from=-"],
                  ["pslCDnaFilter", "-verbose=0",
                   "-minCover=" + str(conf.protTransAlnMinCover),
                   "-minId=" + str(conf.protTransAlnMinId),
                   "/dev/stdin", "/dev/stdout"]], stdout=protTransPsl)

def proteinTranscriptAlign(uniprotFa, transFa, protTransPsl, algo, workDir):
    targetDir = osp.join(workDir, "transDb")
    transDbFa = osp.join(targetDir, "transDb.fa")
    with runIfNotDone(targetDir, depends=transFa) as do:
        if do:
            targetBuildDb(transFa, transDbFa, algo, targetDir)

    queryDir = osp.join(workDir, "queryDir")
    with runIfNotDone(queryDir, depends=uniprotFa) as do:
        if do:
            queryBuildDb(uniprotFa, queryDir)

    alignDir = osp.join(workDir, "aligns")
    with runIfNotDone(alignDir, doneDepends=[targetDir, queryDir]) as do:
        if do:
            prMsg("running alignment batch")
            runBatch([uniprotProteinTranscriptAlignJob, algo], queryDir, transDbFa, alignDir,
                     osp.join(workDir, "batch"))

    with runIfOutOfDate(protTransPsl, doneDepends=alignDir) as do:
        if do:
            with fileOps.AtomicFileCreate(protTransPsl) as tmpPsl:
                combineAligns(alignDir, tmpPsl)
    prMsg("finished")

def main(opts):
    proteinTranscriptAlign(opts.uniprotFa, opts.transFa, opts.protTransPsl, opts.algo, opts.workDir)

main(parseArgs())
